{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning Tutorial with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the [starter tutorial from the official documentation](https://lightning.ai/docs/pytorch/stable/starter/introduction.html), with some added features. In the notebook, an Autoencoder is implemented for the MNIST dataset.\n",
    "\n",
    "Pytorch Lightning uses Pytorch under the hood; however, the usual Pytorch boilerplate code is abstracted to a cleaner implementation similar to Keras. In that implementation, the code is structured in two major classes:\n",
    "\n",
    "- `LightningModule`: this class takes the Pytorch model and expects the definition of some functions, such as:\n",
    "  - `training_step()`\n",
    "  - `validation_step()`\n",
    "  - `test_step()`\n",
    "  - `configure_optimizers()`, which returns the optimizer and the scheduler\n",
    "  - `forward()`\n",
    "  - `predict_step()`\n",
    "- `Trainer`: this class takes the `LightningModule` and the datasets in the form of `Dataloaders` and is able to run these methods:\n",
    "  - `fit()`\n",
    "  - `test()`\n",
    "  - `predict()`\n",
    "\n",
    "In addition to those classes, we also need Pytorch `Dataloaders`.\n",
    "\n",
    "Many nice operations are automatically performed via arguments/flags in the `Trainer` and minor definitions/calls in `LightningModule`:\n",
    "\n",
    "- Epoch and batch iteration\n",
    "- `optimizer.step()`, `loss.backward()`, `optimizer.zero_grad()` calls\n",
    "- Calling of `model.eval()`, enabling/disabling grads during evaluation\n",
    "- [Checkpoint Saving and Loading](https://lightning.ai/docs/pytorch/stable/common/checkpointing.html)\n",
    "- Tensorboard logging (see [loggers](https://lightning.ai/docs/pytorch/stable/visualize/loggers.html) options)\n",
    "- [Multi-GPU](https://lightning.ai/docs/pytorch/stable/accelerators/gpu.html) support\n",
    "- etc.\n",
    "\n",
    "Alltogether, this is a summary of the contents implemented in the notebook:\n",
    "\n",
    "- The encoder/decoder models are created with Pytorch.\n",
    "- A Lightning model is created with `LightningModule`; it has the most common methods:\n",
    "  - `training_step()` with loss computation and logging\n",
    "  - `validation_step()`\n",
    "  - `test_step()`\n",
    "  - `configure_optimizers()`, which returns the optimizer and the scheduler\n",
    "  - `forward()`, if the model is called\n",
    "  - `predict_step()` for using it in `Trainer().predict()`\n",
    "- A `Trainer` is instantiated and `fit()` with:\n",
    "  - `EarlyStopping` passed as a callbac\n",
    "  - Train and validation data loaders\n",
    "- The model is tested with `Trainer().test()`\n",
    "- The checkpoint is loaded and used:\n",
    "  - The Pytorch model is used independently from Lightning\n",
    "  - The `Trainer().predict()` interface is used to predict a dataset\n",
    "- Training is resumed starting with a desired framework.\n",
    "- Logs are visualized with Tensorboard\n",
    "- Interesting `Trainer` tricks are shown\n",
    "  - Learning rate finding\n",
    "  - Accumulated gradient batching\n",
    "  - Mixed precision\n",
    "  - Gradient clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting resources:\n",
    "\n",
    "- [Lightning in 15 Minutes](https://lightning.ai/docs/pytorch/stable/starter/introduction.html)\n",
    "- [How to Organize PyTorch Into Lightning](https://lightning.ai/docs/pytorch/stable/starter/converting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation of the environment and **Lightning**:\n",
    "\n",
    "```bash\n",
    "# Install/activate a basic environment\n",
    "conda env create -f conda.yaml\n",
    "conda activate ds\n",
    "# Alternatively, if you have an env and wnat to install tensorboard\n",
    "python -m pip install lightning\n",
    "\n",
    "# OPTIONAL: Pytorch on Windows + CUDA 11.7\n",
    "# Update your NVIDIA drivers: https://www.nvidia.com/Download/index.aspx\n",
    "# I have version 12.1, but it works with older versions, e.g. 11.7\n",
    "# Check your CUDA version with: nvidia-smi.exe\n",
    "# In case of any runtime errors, check vrsion compatibility tables:\n",
    "# https://github.com/pytorch/vision#installation\n",
    "python -m pip install -U torch==1.13+cu117 torchvision==0.14+cu117 torchaudio torchtext==0.14 --index-url https://download.pytorch.org/whl/cu117\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "# '1.13.0+cu117'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 11 19:06:26 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.23                 Driver Version: 536.23       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060      WDDM  | 00000000:22:00.0 Off |                  N/A |\n",
      "|  0%   38C    P8              14W / 170W |      0MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Get info of all GPU devices\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\n"
     ]
    }
   ],
   "source": [
    "# Set environment variable with possible device ids\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "# Set device: 0 or 1\n",
    "# NOTE: indices are not necessarily the ones shown by nvidia-smi\n",
    "# We need to try them with the cell below\n",
    "torch.cuda.set_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version? 1.13.0+cu117\n",
      "Torchvision version? 0.14.0+cu117\n",
      "Is cuda available? True\n",
      "Is cuDNN version: 8500\n",
      "cuDNN enabled?  True\n",
      "Device count? 1\n",
      "Current device? 0\n",
      "Device name?  NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Check that the selected device is the desired one\n",
    "print(\"Torch version?\", torch.__version__)\n",
    "print(\"Torchvision version?\", torchvision.__version__)\n",
    "print(\"Is cuda available?\", torch.cuda.is_available())\n",
    "print(\"Is cuDNN version:\", torch.backends.cudnn.version())\n",
    "print(\"cuDNN enabled? \", torch.backends.cudnn.enabled)\n",
    "print(\"Device count?\", torch.cuda.device_count())\n",
    "print(\"Current device?\", torch.cuda.current_device())\n",
    "print(\"Device name? \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the Lightning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LightningModule enables your PyTorch nn.Module to play together in complex ways inside the training_step (there is also an optional validation_step and test_step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# ensure reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# define any number of nn.Modules (or use your current ones)\n",
    "# actually, we can define the model outside and then pass\n",
    "# it to the LightningModule\n",
    "# we can also do it with 1-liners\n",
    "# encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "# decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Optional class, not used\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # in this case, the batch is reshaped to (B, 28*28)\n",
    "        return self.decoder(self.encoder(x))    \n",
    "\n",
    "# define the LightningModule\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder, learning_rate=0.001, batch_size=64):\n",
    "        super().__init__()\n",
    "        # the model can be defined here or outside\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        # OPTIONAL: automatically save all the hyperparameters passed to init,\n",
    "        # but exclude things we don't want to save\n",
    "        # NOTE: hyperparams saved to lightning_logs/version_X/hparams.yaml\n",
    "        self.save_hyperparameters(\"learning_rate\", \"batch_size\", ignore=[\"encoder\", \"decoder\"])\n",
    "        # then, hyperparams are also available as\n",
    "        # self.hparams.learning_rate\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop\n",
    "        # it is independent of forward()\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z) # x_hat is (B, 28*28)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss.item()) # important to take .item() to remove computational graph\n",
    "        # If we have a scheduler:\n",
    "        # lr = self.optimizers().param_groups[0]['lr']\n",
    "        # self.log('learning_rate', lr)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop (optional)\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss.item())\n",
    "        # we would return the loss if sth needs to be done on\n",
    "        # hooks like on_validation_end()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop (optional)\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss.item())\n",
    "        # we would return the loss if sth needs to be done on\n",
    "        # hooks like on_test_end()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # intantiate return optimizer and learning rate schedulers\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=70, gamma=0.1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # in this case, the batch is reshaped to (B, 28*28)\n",
    "        return self.decoder(self.encoder(x))\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        # this calls forward\n",
    "        # this will be used in trainer.predict(...)\n",
    "        # we can make this step more sophisticated, if desired\n",
    "        # NOTE: we can also avoid the forward() call\n",
    "        # and implement any desired predict step here!\n",
    "        return self(batch[0]) # a batch is a list with one batch inside, so we take element 0\n",
    "\n",
    "\n",
    "# init the autoencoder\n",
    "encoder = Encoder() # nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "decoder = Decoder() # nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "autoencoder = LitAutoEncoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightning supports ANY iterable (DataLoader, numpy, etc…) for the train/val/test/predict splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data\n",
    "train_set = MNIST(os.path.join(os.getcwd(), \"data\"), download=True, transform=ToTensor())\n",
    "test_set = MNIST(os.path.join(os.getcwd(), \"data\"), download=True, train=False, transform=ToTensor())\n",
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = utils.data.random_split(train_set, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "# loaders\n",
    "# we can/should define batch_size as a hyperparameter in the LightningModule to be able to tune it\n",
    "# but the trainer.text() which uses the test_loader does not use the hyperparameter\n",
    "# HOWEVER, the recommended way is to tune/find the batch size and then instantiate the loaders with a hard-coded value\n",
    "train_loader = utils.data.DataLoader(train_set) # , batch_size=64)\n",
    "valid_loader = utils.data.DataLoader(valid_set) #, batch_size=64)\n",
    "test_loader = utils.data.DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lightning [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) “mixes” any [LightningModule](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html) with any dataset and abstracts away all the engineering complexity needed for scale.\n",
    "\n",
    "The Lightning [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) automates [40+ tricks](https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-flags) including:\n",
    "\n",
    "- Epoch and batch iteration\n",
    "- `optimizer.step()`, `loss.backward()`, `optimizer.zero_grad()` calls\n",
    "- Calling of `model.eval()`, enabling/disabling grads during evaluation\n",
    "- [Checkpoint Saving and Loading](https://lightning.ai/docs/pytorch/stable/common/checkpointing.html)\n",
    "- Tensorboard logging (see [loggers](https://lightning.ai/docs/pytorch/stable/visualize/loggers.html) options)\n",
    "- [Multi-GPU](https://lightning.ai/docs/pytorch/stable/accelerators/gpu.html) support\n",
    "- [TPU](https://lightning.ai/docs/pytorch/stable/accelerators/tpu.html)\n",
    "- [16-bit precision](https://lightning.ai/docs/pytorch/stable/advanced/speed.html#speed-amp) AMP support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important functionalities to improve our training is [early stopping](https://lightning.ai/docs/pytorch/stable/common/early_stopping.html), which is implemented with callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", # must be saved with self.log() in the LightningModule\n",
    "    min_delta=0.00, # minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode=\"min\" # or max if val_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can also use the `ModelCheckpoint` callback to save both the last and the best model in our specified folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "# NOTE: if no ModelCheckpoint is specified, after each epoch the model checkpoint\n",
    "# is saved in ./lightning_logs/version_X/checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss', # which metric to monitor\n",
    "    dirpath='./output_mnist',  # specify the path to save the checkpoints\n",
    "    filename='best',  # best.ckpt - we can also use naming formats: {epoch}-{val_loss:.2f}\n",
    "    save_last=True,  # ensures that the last epoch's model is saved: last.ckpt\n",
    "    mode='min',  # save the model with the minimum 'val_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that logs will be automatically written to `./lightning_logs` using Tensorboard (default); if we want to control logging, we can do it as follows:\n",
    "\n",
    "```python\n",
    "from lightning.pytorch.loggers import TensorBoardLogger # other loggers are also available!\n",
    "\n",
    "# Create the logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"logs/\", # folder\n",
    "    name=\"my_experiment\",\n",
    "    version=\"1\" # if no version passed, it will be automatically incremented\n",
    ")\n",
    "\n",
    "# Pass the logger to the Trainer\n",
    "trainer = Trainer(logger=logger)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K\n",
      "1 | decoder | Decoder | 51.2 K\n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535d92dd9edd467781bd323a2e6c96d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1c1b0bb7ac45b4889a74c4788a0510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403709d03d8f40b2a70a85f545c9eb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "# if GPU is available, we can invoke it with the accelerator flag\n",
    "# the checkpoint and the logs are saved to lightining_logs/version_X\n",
    "trainer = pl.Trainer(\n",
    "    # OPTIONAL arguments\n",
    "    limit_train_batches=100,\n",
    "    limit_val_batches=100,\n",
    "    limit_test_batches=100,\n",
    "    max_epochs=1,\n",
    "    accelerator=\"gpu\", # \"mps\" for Apple Silicon! Metal Performance Shaders\n",
    "    devices=1, # in case we have several GPUs\n",
    "    callbacks=[early_stop_callback, checkpoint_callback]\n",
    "    # if we want to disable saving / checkpointing\n",
    "    # enable_checkpointing=False\n",
    "    # if we want to control the directory where the checkpoint is saved\n",
    "    # default_root_dir=\"some/path/\"\n",
    ")\n",
    "trainer.fit(\n",
    "    model=autoencoder,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=valid_loader\n",
    "    # if we want to resume training where we left\n",
    "    # ckpt_path=\"some/path/to/my_checkpoint.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c07c9423cac4d868a8f677b37620e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06443773210048676    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06443773210048676   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.06443773210048676}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model\n",
    "# WARNING: We should first load the best model and then run .test(),\n",
    "# see below how to load the best model\n",
    "trainer.test(model=autoencoder,\n",
    "             dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Checkpoint and Use the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we’ve trained the model you can export to onnx, torchscript and put it into production or simply load the weights and run predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n",
      "{'learning_rate': 0.001, 'batch_size': 64}\n",
      "⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡ \n",
      "Predictions (4 image embeddings):\n",
      " tensor([[-0.8746, -0.5090, -0.5199],\n",
      "        [-0.8949, -0.4956, -0.5267],\n",
      "        [-0.8948, -0.3335, -0.4570],\n",
      "        [-0.8834, -0.5024, -0.5150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) \n",
      " ⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡\n"
     ]
    }
   ],
   "source": [
    "# load checkpoint as Lightning object\n",
    "# check logs path for correct version_X and checkpoint\n",
    "#checkpoint = \"./lightning_logs/version_19/checkpoints/epoch=0-step=100.ckpt\"\n",
    "checkpoint = \"./output_mnist/best.ckpt\"\n",
    "lit_autoencoder = LitAutoEncoder.load_from_checkpoint(checkpoint, encoder=Encoder(), decoder=Decoder())\n",
    "\n",
    "# We should run trainer.test() now\n",
    "\n",
    "# we can also load the checkpoint with torch\n",
    "# many things are saved: 'state_dict', 'optimizer_states', 'hyper_parameters', etc.\n",
    "checkpoint_torch = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "print(checkpoint_torch.keys())\n",
    "print(checkpoint_torch[\"hyper_parameters\"])\n",
    "\n",
    "# choose your trained nn.Module\n",
    "# having the model defined outside makes it easier to use it later\n",
    "encoder = lit_autoencoder.encoder\n",
    "encoder.eval()\n",
    "\n",
    "# embed 4 fake images!\n",
    "fake_image_batch = torch.rand(4, 28 * 28, device=lit_autoencoder.device)\n",
    "embeddings = encoder(fake_image_batch)\n",
    "print(\"⚡\" * 20, \"\\nPredictions (4 image embeddings):\\n\", embeddings, \"\\n\", \"⚡\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a915820baa43fc8580866059784d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Also, it is possible to use the forward() and the predict_step() functions\n",
    "# of the LitAutoencoder from the Trainer\n",
    "# NOTE that predict_step() is called\n",
    "trainer = pl.Trainer()\n",
    "predictions = trainer.predict(model=lit_autoencoder, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of batches\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch 0, all outputs from Autoencoder: (B, 28*28)\n",
    "# NOTE that in this implementation the images were not resized to 28x28\n",
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./lightning_logs\n",
    "# http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Extract Tensorboard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Keys: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['hp_metric', 'train_loss', 'epoch', 'val_loss', 'test_loss'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
      "Scalar Tags: ['hp_metric', 'train_loss', 'epoch', 'val_loss', 'test_loss']\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "# Path to the TensorBoard log directory\n",
    "# NOTE that we check in the folder structure the metric we want...\n",
    "#log_dir = \"./runs/fashion_mnist_experiment_1/\"\n",
    "log_dir = './lightning_logs/version_44'\n",
    "#log_dir = './runs/fashion_mnist_experiment_1/Training vs. Validation Loss_Validation/'\n",
    "\n",
    "# Load the TensorBoard event files\n",
    "event_acc = event_accumulator.EventAccumulator(log_dir)\n",
    "event_acc.Reload()\n",
    "\n",
    "# Print the list of events\n",
    "print(\"Event Keys:\", event_acc.Tags())\n",
    "\n",
    "# Print the list of scalar tags\n",
    "print(\"Scalar Tags:\", event_acc.scalars.Keys()) # This output should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric Values: [0.08668341487646103, 0.05452636629343033]\n"
     ]
    }
   ],
   "source": [
    "# Get the scalar events (train and validation losses)\n",
    "metric = event_acc.Scalars('train_loss')\n",
    "\n",
    "# Extract the loss values as Python lists\n",
    "metric_values = [event.value for event in metric]\n",
    "\n",
    "# Print the extracted loss values\n",
    "print(\"Metric Values:\", metric_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Re-Train or Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at ./output_mnist/best.ckpt\n",
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:247: UserWarning: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\", \"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\"].\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K\n",
      "1 | decoder | Decoder | 51.2 K\n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at ./output_mnist/best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dae8599a1734605b77f2df16be16619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Msagardi\\AppData\\Local\\anaconda3\\envs\\ds\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "#encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "#decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "autoencoder = LitAutoEncoder(encoder, decoder)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    limit_train_batches=100,\n",
    "    limit_val_batches=100,\n",
    "    limit_test_batches=100,\n",
    "    max_epochs=1,\n",
    "    accelerator=\"gpu\"\n",
    ")\n",
    "\n",
    "# automatically restores model, epoch, step, LR schedulers, etc...\n",
    "trainer.fit(\n",
    "    model=autoencoder,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=valid_loader,\n",
    "    #ckpt_path=\"./lightning_logs/version_44/checkpoints/epoch=0-step=100.ckpt\"\n",
    "    ckpt_path=\"./output_mnist/best.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Trainer Tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "- [Training Tricks](https://lightning.ai/docs/pytorch/stable/advanced/training_tricks.html)\n",
    "- [Trainer Flags](https://lightning.ai/docs/pytorch/stable/common/trainer.html)\n",
    "- [Trainer API](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "model = LitAutoEncoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Batch Size Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning: **Warning: This did not work.**\n",
    "\n",
    "```python\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "# Usually we know the possible batch size, but we can find it, too\n",
    "# Usually we want to have the largest batch size possible\n",
    "# For this to work, we need in the LightningModule, either\n",
    "# self.batch_size\n",
    "# self.hparams.batch_size\n",
    "# HOWEVER, the recommended way is to tune/find the batch size and then instantiate the loaders with a hard-coded value\n",
    "\n",
    "# Create a tuner for the trainer\n",
    "trainer = pl.Trainer()\n",
    "tuner = Tuner(trainer)\n",
    "\n",
    "# Auto-scale batch size by growing it exponentially (default)\n",
    "tuner.scale_batch_size(model, train_dataloaders=train_loader, val_dataloaders=valid_loader, mode=\"power\")\n",
    "\n",
    "# Auto-scale batch size with binary search\n",
    "tuner.scale_batch_size(model, train_dataloaders=train_loader, val_dataloaders=valid_loader, mode=\"binsearch\")\n",
    "\n",
    "# THEN:\n",
    "# Fit as normal with new batch size\n",
    "# trainer.fit(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c605baa2de14b76aedb17687fce3cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 95 steps due to diverging loss.\n",
      "Learning rate set to 1.0964781961431852e-07\n",
      "Restoring states from the checkpoint path at c:\\Users\\Msagardi\\git_repositories\\tool_guides\\pytorch_lightning\\.lr_find_b540e2bc-58f4-44c6-96c3-324f5751bb4f.ckpt\n",
      "Restored all states from the checkpoint at c:\\Users\\Msagardi\\git_repositories\\tool_guides\\pytorch_lightning\\.lr_find_b540e2bc-58f4-44c6-96c3-324f5751bb4f.ckpt\n",
      "C:\\Users\\Msagardi\\AppData\\Local\\Temp\\ipykernel_78204\\3095258436.py:13: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [1e-08, 1.4454397707459274e-08, 1.7378008287493753e-08, 2.0892961308540398e-08, 2.51188643150958e-08, 3.019951720402016e-08, 3.630780547701014e-08, 4.36515832240166e-08, 5.248074602497726e-08, 6.309573444801934e-08, 7.585775750291837e-08, 9.120108393559096e-08, 1.0964781961431852e-07, 1.3182567385564074e-07, 1.5848931924611133e-07, 1.9054607179632475e-07, 2.2908676527677735e-07, 2.7542287033381663e-07, 3.311311214825911e-07, 3.9810717055349735e-07, 4.786300923226383e-07, 5.75439937337157e-07, 6.918309709189366e-07, 8.317637711026709e-07, 1e-06, 1.2022644346174132e-06, 1.445439770745928e-06, 1.7378008287493761e-06, 2.089296130854039e-06, 2.5118864315095797e-06, 3.0199517204020163e-06, 3.630780547701014e-06, 4.365158322401661e-06, 5.248074602497728e-06, 6.3095734448019305e-06, 7.585775750291836e-06, 9.120108393559096e-06, 1.0964781961431852e-05, 1.3182567385564076e-05, 1.584893192461114e-05, 1.9054607179632464e-05, 2.2908676527677725e-05, 2.7542287033381663e-05, 3.311311214825911e-05, 3.9810717055349735e-05, 4.786300923226385e-05, 5.7543993733715664e-05, 6.918309709189363e-05, 8.317637711026709e-05, 0.0001, 0.00012022644346174131, 0.0001445439770745928, 0.00017378008287493763, 0.0002089296130854041, 0.0002511886431509582, 0.0003019951720402019, 0.000363078054770101, 0.0004365158322401656, 0.0005248074602497723, 0.000630957344480193, 0.0007585775750291836, 0.0009120108393559097, 0.0010964781961431851, 0.0013182567385564075, 0.001584893192461114, 0.0019054607179632484, 0.0022908676527677745, 0.002754228703338169, 0.003311311214825908, 0.003981071705534969, 0.00478630092322638, 0.005754399373371567, 0.006918309709189364, 0.008317637711026709, 0.01, 0.012022644346174132, 0.01445439770745928, 0.017378008287493765, 0.02089296130854041, 0.025118864315095822, 0.030199517204020192, 0.036307805477010104, 0.04365158322401657, 0.05248074602497723, 0.0630957344480193, 0.07585775750291836, 0.09120108393559097, 0.10964781961431852, 0.13182567385564073, 0.15848931924611143, 0.19054607179632482, 0.2290867652767775, 0.2754228703338169, 0.3311311214825908, 0.3981071705534969], 'loss': [0.15997176218514472, 0.1423715431217335, 0.14411844250723668, 0.1411264079604949, 0.1305138137471967, 0.1404046094515364, 0.13304568142866224, 0.12927801222922566, 0.1384205862689445, 0.1345221772338932, 0.13414787708922318, 0.13954607354190707, 0.13586515411777017, 0.13160485060562782, 0.13739847243195893, 0.14091974422928513, 0.1394694122180092, 0.13734018688384841, 0.14134110840473368, 0.1430643018596689, 0.1430114363118817, 0.1410004702278739, 0.13993632007681886, 0.14279775934449657, 0.14278678351002905, 0.14361480384903938, 0.141174908553287, 0.14126579578320245, 0.1408187723852219, 0.14257387480094608, 0.14187810705749443, 0.1391496650993077, 0.13921030712932317, 0.13951592433381318, 0.1375927882506168, 0.13557386812963473, 0.13360756028775342, 0.13342801037928262, 0.13247469629596767, 0.13276029884408605, 0.13209554040275523, 0.1312423730506515, 0.1344787994593503, 0.13333005936438164, 0.1340377770652294, 0.1335104554524396, 0.1357526406330289, 0.1357071751322241, 0.13618442481981607, 0.13678297390897787, 0.1388282533863425, 0.13816949677154314, 0.13768567145500435, 0.13784382043626614, 0.13808400468731, 0.13745055179971777, 0.13910223048025908, 0.1378377115967852, 0.13726768612432472, 0.13534400367972904, 0.13498347774566374, 0.13428718021576067, 0.1327429200348814, 0.13118876528732987, 0.12954437813390135, 0.12885946775244564, 0.12839786827535324, 0.12806725745593803, 0.12717134800675742, 0.12892530042588687, 0.12808191954845569, 0.1266721601377614, 0.12511553745940027, 0.1237180126338758, 0.1218679396842652, 0.12022062482146957, 0.11896690962054249, 0.11780283886317966, 0.11711200142117222, 0.11598363378562576, 0.11684370854384986, 0.115588425809419, 0.11435651897345699, 0.11383078987613866, 0.11314495757663466, 0.11184901513103233, 0.11078675155909831, 0.10998474547936388, 0.10924162910968577, 0.10755819321274494, 0.10777993567710173, 0.10720032191789393, 0.10721350904171044, 0.10672197188663779, 2.9522381144858256]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate Trainer and Tuner\n",
    "trainer = pl.Trainer()\n",
    "tuner = Tuner(trainer)\n",
    "\n",
    "# Run learning rate finder\n",
    "# https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.tuner.tuning.Tuner.html#lightning.pytorch.tuner.tuning.Tuner\n",
    "lr_finder = tuner.lr_find(model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "\n",
    "# Results can be found in\n",
    "print(lr_finder.results)\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "# update hparams of the model\n",
    "model.learning_rate = new_lr\n",
    "model.hparams.learning_rate = new_lr\n",
    "\n",
    "# THEN:\n",
    "# Fit model\n",
    "# trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Clipping to Avoid Exploding/Vanishing Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# DEFAULT (ie: don't clip)\n",
    "trainer = Trainer(gradient_clip_val=0)\n",
    "\n",
    "# clip gradients' global norm to <=0.5 using gradient_clip_algorithm='norm' by default\n",
    "trainer = Trainer(gradient_clip_val=0.5)\n",
    "\n",
    "# clip gradients' maximum magnitude to <=0.5\n",
    "trainer = Trainer(gradient_clip_val=0.5, gradient_clip_algorithm=\"value\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accummulate Gradient Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# accumulate every 4 batches (effective batch size is batch*4)\n",
    "trainer = Trainer(accumulate_grad_batches=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lightning supports either double (64, default), float (32), bfloat16 (bf16), or half (16) precision training.\n",
    "> Half precision, or mixed precision, is the combined use of 32 and 16 bit floating points to reduce memory footprint during model training.\n",
    "> This can result in improved performance, achieving +3X speedups on modern GPUs.\n",
    "\n",
    "```python\n",
    "# default used by the Trainer\n",
    "trainer = Trainer(precision=32)\n",
    "\n",
    "# 16-bit precision\n",
    "trainer = Trainer(precision=\"16-mixed\", accelerator=\"gpu\", devices=1)  # works only on CUDA\n",
    "\n",
    "# bfloat16 precision\n",
    "trainer = Trainer(precision=\"bf16-mixed\")\n",
    "\n",
    "# 64-bit precision\n",
    "trainer = Trainer(precision=64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Other Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Profiler: get time spent in each function call\n",
    "trainer = Trainer(profiler=True)\n",
    "\n",
    "# Number of epochs\n",
    "trainer = Trainer(max_epochs=100)\n",
    "\n",
    "# Limit number of batches (for testing); also: limit_val_batches, limit_test_batches\n",
    "trainer = Trainer(limit_train_batches=100)\n",
    "\n",
    "# Logging; default is 50\n",
    "trainer = Trainer(log_every_n_steps=50)\n",
    "\n",
    "# Use deterministic algos, but slower; defaults to False\n",
    "trainer = Trainer(deterministic=True)\n",
    "\n",
    "# Faster on GPUs if sizes don't change\n",
    "trainer = Trainer(benchmark=True)\n",
    "\n",
    "# The trainer has also properties!\n",
    "trainer.current_epoch\n",
    "trainer.logged_metrics\n",
    "trainer.num_training_batches\n",
    "trainer.train_dataloader\n",
    "trainer.logger\n",
    "#...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interesting Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Log histograms of weights: [Track and Visualize Experiments](https://lightning.ai/docs/pytorch/stable/visualize/logging_intermediate.html)\n",
    "- Save checkpoints by condition: [Customize checkpointing behavior](https://lightning.ai/docs/pytorch/stable/common/checkpointing_intermediate.html)\n",
    "- [Debugging](https://lightning.ai/docs/pytorch/stable/debug/debugging_basic.html)\n",
    "- [Profiling](https://lightning.ai/docs/pytorch/stable/tuning/profiler_basic.html)\n",
    "- [Deploy models into production with ONNX](https://lightning.ai/docs/pytorch/stable/deploy/production_advanced.html)\n",
    "- [Customize the Trainer with Callbacks](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html)\n",
    "- [Effective Training Tricks](https://lightning.ai/docs/pytorch/stable/advanced/training_tricks.html)\n",
    "  - Accumulate gradient batches\n",
    "  - Gradient clipping\n",
    "  - Stochastic Weight Averaging\n",
    "  - Batch Size Finder\n",
    "  - Learning Rate Finder\n",
    "  - N-Bit precision\n",
    "    - [Basic](https://lightning.ai/docs/pytorch/stable/common/precision_basic.html)\n",
    "    - [Intermediate](https://lightning.ai/docs/pytorch/stable/common/precision_intermediate.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
