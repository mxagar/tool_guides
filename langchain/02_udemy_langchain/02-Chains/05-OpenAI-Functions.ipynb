{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcded1a6-2430-4707-a78c-c82f4c5ee6fc",
   "metadata": {},
   "source": [
    "<a href = \"https://www.pieriantraining.com\"><img src=\"../PT Centered Purple.png\"> </a>\n",
    "\n",
    "<em style=\"text-align:center\">Copyrighted by Pierian Training</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
   "metadata": {},
   "source": [
    "#  Using OpenAI Functions API\n",
    "\n",
    "The latest OpenAI models allow you to specify the model to output JSON results.\n",
    "Langchain already had a lot of tools and prompts for this purpose, but OpenAI also released a slightly more fine-tuned and steerable version that can help always get JSON out.\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9f515b-e5b1-4893-97db-f400452b3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69bea346-469b-4d87-9b35-186b09ccff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40fb4a66-3907-4a97-a86a-cd987de3cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the correct model based on: \n",
    "# https://platform.openai.com/docs/models/\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8dbbab7-c1de-4056-8919-2d630b171029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a class we'd like to fill in with outputs from LLMs\n",
    "# LLMs return text, but using Function Calling\n",
    "# we can enforce some structure in the returns\n",
    "class Scientist():\n",
    "    def __init__(self,first_name,last_name):\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1848a950-5db3-4601-bd5a-28d41054e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a JSON schema that specified\n",
    "# the structure of the return data\n",
    "json_schema = {\n",
    "  \"title\": \"Scientist\",\n",
    "  \"description\": \"Information about a famous scientist\",\n",
    "  \"type\": \"object\",\n",
    "  # properties is the dict used by OpenAI\n",
    "  # we need to define the fields we want as shown here\n",
    "  \"properties\": {\n",
    "      \"first_name\": {\n",
    "        'title':'First Name',\n",
    "        'description': \"First name of scientist\",\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"last_name\":{\n",
    "        'title':'Last Name',\n",
    "        'description': \"Last name of scientist\",\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "  },\n",
    "  \"required\": ['first_name','last_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcfe6f6e-a53f-40cc-9ffe-3e2de3118573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = 'Name a famous {country} scientist'\n",
    "#human_prompt = HumanMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa14396f-c442-4463-a084-b57d2f0509f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we create the chain but enforce the structure in the chat/LLM\n",
    "chain = chat_prompt|llm.with_structured_output(schema=json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66870bf-da8c-4e73-9a17-94a7f46d10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"country\": \"Indian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd5cabc-e379-4989-bda1-3a2e1874fd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'C.V.', 'last_name': 'Raman'}\n"
     ]
    }
   ],
   "source": [
    "print(result) # {'first_name': 'A.P.J.', 'last_name': 'Abdul Kalam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61165a84-05ad-4fb7-ac7f-ea981fd8e092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result) # dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c7df9-d3f7-4422-9f30-4fd82424873b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
