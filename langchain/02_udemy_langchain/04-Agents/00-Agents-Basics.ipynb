{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents: Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load the OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.agents.load_tools import get_all_tool_names\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tools/agents, use temeprature=0 to get deterministic results\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrations > Tools:\n",
    "# https://python.langchain.com/v0.2/docs/integrations/tools/\n",
    "tools = load_tools([\"llm-math\"], llm=llm) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.tools.Tool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load_tools returns a list of the tools related to the tool names we input\n",
    "#len(tools) # 1\n",
    "type(tools[0]) # langchain_core.tools.Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep', 'wolfram-alpha', 'google-search', 'google-search-results-json', 'searx-search-results-json', 'bing-search', 'metaphor-search', 'ddg-search', 'google-lens', 'google-serper', 'google-scholar', 'google-finance', 'google-trends', 'google-jobs', 'google-serper-results-json', 'searchapi', 'searchapi-results-json', 'serpapi', 'dalle-image-generator', 'twilio', 'searx-search', 'merriam-webster', 'wikipedia', 'arxiv', 'golden-query', 'pubmed', 'human', 'awslambda', 'stackexchange', 'sceneXplain', 'graphql', 'openweathermap-api', 'dataforseo-api-search', 'dataforseo-api-search-json', 'eleven_labs_text2speech', 'google_cloud_texttospeech', 'read_file', 'reddit_search', 'news-api', 'tmdb-api', 'podcast-api', 'memorize', 'llm-math', 'open-meteo-api', 'requests', 'requests_get', 'requests_post', 'requests_patch', 'requests_put', 'requests_delete', 'terminal']\n"
     ]
    }
   ],
   "source": [
    "# Get all tool names\n",
    "all_tool_names = get_all_tool_names()\n",
    "print(all_tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"llm-math\" in all_tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAT_CONVERSATIONAL_REACT_DESCRIPTION',\n",
       " 'CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
       " 'CONVERSATIONAL_REACT_DESCRIPTION',\n",
       " 'OPENAI_FUNCTIONS',\n",
       " 'OPENAI_MULTI_FUNCTIONS',\n",
       " 'REACT_DOCSTORE',\n",
       " 'SELF_ASK_WITH_SEARCH',\n",
       " 'STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
       " 'ZERO_SHOT_REACT_DESCRIPTION',\n",
       " '__class__',\n",
       " '__doc__',\n",
       " '__members__',\n",
       " '__module__']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir: return an alphabetized list of names comprising \n",
    "# (some of) the attributes of the given object, \n",
    "# and of attributes reachable from it\n",
    "# Here, we get all the AgentTypes\n",
    "dir(AgentType)\n",
    "# 'CHAT_CONVERSATIONAL_REACT_DESCRIPTION',\n",
    "# 'CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
    "# 'CONVERSATIONAL_REACT_DESCRIPTION',\n",
    "# 'OPENAI_FUNCTIONS',\n",
    "# 'OPENAI_MULTI_FUNCTIONS',\n",
    "# 'REACT_DOCSTORE',\n",
    "# 'SELF_ASK_WITH_SEARCH',\n",
    "# 'STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
    "# 'ZERO_SHOT_REACT_DESCRIPTION': no examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\A200239740\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# We create a Zero-shot Agent\n",
    "# WARNING: initialize_agent is deprecated...\n",
    "# Instead, we should use new agent constructor methods:\n",
    "# create_react_agent, create_json_agent, create_structured_chat_agent, ...\n",
    "agent = initialize_agent(\n",
    "    tools, # LLM-Math\n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True # check what is happening inside\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\A200239740\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Calculator tool to multiply these two numbers.\n",
      "Action: Calculator\n",
      "Action Input: 123456, 29748\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 153204\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 123456 multiplied by 29748 is 3,672,076,288\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'123456 multiplied by 29748 is 3,672,076,288'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is 123456 multiplied by 29748?\") # 3672569088\n",
    "# > Entering new AgentExecutor chain...\n",
    "# I need to multiply 123456 by 29748.\n",
    "# Action: Calculator\n",
    "# Action Input: 123456 * 29748\n",
    "# Observation: Answer: 3672569088\n",
    "# Thought:I now know the final answer\n",
    "# Final Answer: 3672569088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same example but with the new interface\n",
    "# https://api.python.langchain.com/en/latest/langchain_api_reference.html#module-langchain.agents\n",
    "# https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 123456 multiplied by 29748?', 'output': '153204'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is 123456 multiplied by 29748?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
