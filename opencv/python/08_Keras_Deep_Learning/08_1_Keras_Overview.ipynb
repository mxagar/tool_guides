{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Keras Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect whether bank notes are forged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# read CSV tables\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 columns x 1372 rows (samples)\n",
    "# column 0-3: input features, already extracted\n",
    "# column 4: label = 0 forgery, 1 real\n",
    "data = genfromtxt('../../data/bank_note_data.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Scikit-Learn for splitting the dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split Shift TAB, scroll down to example\n",
    "# it is important to randomize\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8734  , -0.033118, -0.20165 ,  0.55774 ],\n",
       "       [ 2.0177  ,  1.7982  , -2.9581  ,  0.2099  ],\n",
       "       [-0.36038 ,  4.1158  ,  3.1143  , -0.37199 ],\n",
       "       ...,\n",
       "       [-7.0364  ,  9.2931  ,  0.16594 , -4.5396  ],\n",
       "       [-3.4605  ,  2.6901  ,  0.16165 , -1.0224  ],\n",
       "       [-3.3582  , -7.2404  , 11.4419  , -0.57113 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(919,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.1116"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.2869"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a scaler object,\n",
    "# fit the X_train to it (min-max range)\n",
    "# and then transform it (scale to the range [0,1])\n",
    "scaler_object = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_object.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler_object.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: we fit (select scaling min-max range) to the TRAIN split only,\n",
    "# because otherwise we're extracting info from the test split\n",
    "# if a test sample has the max (peak) value!\n",
    "scaled_X_test = scaler_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.02679563427227"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0010694864308909147"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a neural network model & train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The official API of Tensorfflow is Keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "# We use fully-connected layers in this example\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model, then add the layers\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer: neurons, input dimenstion, activation\n",
    "# input dimension is necessary only for the input layer\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "\n",
    "# Add hidden layer: neurons, activation function\n",
    "# Often we use something between 1x - 2x the neurons in the input layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add ouput layer\n",
    "# The output layer should have the sigmoid activation to fit the result to [0,1]\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compile the model and define\n",
    "# loss function, optimization strategy, the metric used\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 69\n",
      "Trainable params: 69\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 919 samples\n",
      "Epoch 1/50\n",
      "919/919 - 1s - loss: 0.6683 - accuracy: 0.6844\n",
      "Epoch 2/50\n",
      "919/919 - 0s - loss: 0.6576 - accuracy: 0.6159\n",
      "Epoch 3/50\n",
      "919/919 - 0s - loss: 0.6459 - accuracy: 0.6594\n",
      "Epoch 4/50\n",
      "919/919 - 0s - loss: 0.6316 - accuracy: 0.7095\n",
      "Epoch 5/50\n",
      "919/919 - 0s - loss: 0.6177 - accuracy: 0.7127\n",
      "Epoch 6/50\n",
      "919/919 - 0s - loss: 0.6026 - accuracy: 0.8085\n",
      "Epoch 7/50\n",
      "919/919 - 0s - loss: 0.5861 - accuracy: 0.8324\n",
      "Epoch 8/50\n",
      "919/919 - 0s - loss: 0.5678 - accuracy: 0.8346\n",
      "Epoch 9/50\n",
      "919/919 - 0s - loss: 0.5479 - accuracy: 0.8400\n",
      "Epoch 10/50\n",
      "919/919 - 0s - loss: 0.5270 - accuracy: 0.8390\n",
      "Epoch 11/50\n",
      "919/919 - 0s - loss: 0.5056 - accuracy: 0.8564\n",
      "Epoch 12/50\n",
      "919/919 - 0s - loss: 0.4840 - accuracy: 0.8531\n",
      "Epoch 13/50\n",
      "919/919 - 0s - loss: 0.4618 - accuracy: 0.8651\n",
      "Epoch 14/50\n",
      "919/919 - 0s - loss: 0.4396 - accuracy: 0.8672\n",
      "Epoch 15/50\n",
      "919/919 - 0s - loss: 0.4167 - accuracy: 0.8760\n",
      "Epoch 16/50\n",
      "919/919 - 0s - loss: 0.3942 - accuracy: 0.8879\n",
      "Epoch 17/50\n",
      "919/919 - 0s - loss: 0.3724 - accuracy: 0.8879\n",
      "Epoch 18/50\n",
      "919/919 - 0s - loss: 0.3510 - accuracy: 0.8912\n",
      "Epoch 19/50\n",
      "919/919 - 0s - loss: 0.3320 - accuracy: 0.9021\n",
      "Epoch 20/50\n",
      "919/919 - 0s - loss: 0.3110 - accuracy: 0.9032\n",
      "Epoch 21/50\n",
      "919/919 - 0s - loss: 0.2925 - accuracy: 0.9097\n",
      "Epoch 22/50\n",
      "919/919 - 0s - loss: 0.2753 - accuracy: 0.9206\n",
      "Epoch 23/50\n",
      "919/919 - 0s - loss: 0.2587 - accuracy: 0.9282\n",
      "Epoch 24/50\n",
      "919/919 - 0s - loss: 0.2462 - accuracy: 0.9391\n",
      "Epoch 25/50\n",
      "919/919 - 0s - loss: 0.2313 - accuracy: 0.9412\n",
      "Epoch 26/50\n",
      "919/919 - 0s - loss: 0.2186 - accuracy: 0.9478\n",
      "Epoch 27/50\n",
      "919/919 - 0s - loss: 0.2083 - accuracy: 0.9478\n",
      "Epoch 28/50\n",
      "919/919 - 0s - loss: 0.1973 - accuracy: 0.9499\n",
      "Epoch 29/50\n",
      "919/919 - 0s - loss: 0.1882 - accuracy: 0.9499\n",
      "Epoch 30/50\n",
      "919/919 - 0s - loss: 0.1793 - accuracy: 0.9543\n",
      "Epoch 31/50\n",
      "919/919 - 0s - loss: 0.1709 - accuracy: 0.9543\n",
      "Epoch 32/50\n",
      "919/919 - 0s - loss: 0.1634 - accuracy: 0.9576\n",
      "Epoch 33/50\n",
      "919/919 - 0s - loss: 0.1563 - accuracy: 0.9608\n",
      "Epoch 34/50\n",
      "919/919 - 0s - loss: 0.1500 - accuracy: 0.9576\n",
      "Epoch 35/50\n",
      "919/919 - 0s - loss: 0.1437 - accuracy: 0.9619\n",
      "Epoch 36/50\n",
      "919/919 - 0s - loss: 0.1375 - accuracy: 0.9619\n",
      "Epoch 37/50\n",
      "919/919 - 0s - loss: 0.1324 - accuracy: 0.9630\n",
      "Epoch 38/50\n",
      "919/919 - 0s - loss: 0.1267 - accuracy: 0.9674\n",
      "Epoch 39/50\n",
      "919/919 - 0s - loss: 0.1219 - accuracy: 0.9717\n",
      "Epoch 40/50\n",
      "919/919 - 0s - loss: 0.1187 - accuracy: 0.9717\n",
      "Epoch 41/50\n",
      "919/919 - 0s - loss: 0.1128 - accuracy: 0.9739\n",
      "Epoch 42/50\n",
      "919/919 - 0s - loss: 0.1089 - accuracy: 0.9739\n",
      "Epoch 43/50\n",
      "919/919 - 0s - loss: 0.1049 - accuracy: 0.9761\n",
      "Epoch 44/50\n",
      "919/919 - 0s - loss: 0.1010 - accuracy: 0.9750\n",
      "Epoch 45/50\n",
      "919/919 - 0s - loss: 0.0985 - accuracy: 0.9826\n",
      "Epoch 46/50\n",
      "919/919 - 0s - loss: 0.0945 - accuracy: 0.9793\n",
      "Epoch 47/50\n",
      "919/919 - 0s - loss: 0.0914 - accuracy: 0.9848\n",
      "Epoch 48/50\n",
      "919/919 - 0s - loss: 0.0882 - accuracy: 0.9826\n",
      "Epoch 49/50\n",
      "919/919 - 0s - loss: 0.0849 - accuracy: 0.9848\n",
      "Epoch 50/50\n",
      "919/919 - 0s - loss: 0.0822 - accuracy: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91f42cee90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model: X & y are passed, and the number of epochs\n",
    "# In an epoch, teh whole dataset is used for training once\n",
    "# With verbose, the loss and accuracy are displayed for each epoch\n",
    "model.fit(scaled_X_train, y_train, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer test split and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the confussion matrix with TP, TN, FP, FN\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254,   3],\n",
       "       [  3, 193]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       257\n",
      "         1.0       0.98      0.98      0.98       196\n",
      "\n",
      "    accuracy                           0.99       453\n",
      "   macro avg       0.99      0.99      0.99       453\n",
      "weighted avg       0.99      0.99      0.99       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_super_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = load_model('my_super_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can infer as before\n",
    "y_pred = newmodel.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
