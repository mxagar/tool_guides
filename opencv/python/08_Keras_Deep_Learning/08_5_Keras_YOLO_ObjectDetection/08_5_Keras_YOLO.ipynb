{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 YOLO: Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO = You Only Look Once. Version v3 is analyzed here, v1 was published in 2016 by FAIR.\n",
    "\n",
    "The model receives an image and outputs AABBs of detected object classes known to it.\n",
    "\n",
    "Prior object detection models used to apply several models to different regions and scales. YOLO applies one model to each image (thus, You Only Look Once). The network divides the imge into regions and predicts bounding boxes and probabilities for each region.\n",
    "\n",
    "As a result, YOLO is much faster (100x-1000x) than alternatives.\n",
    "\n",
    "The code can be downloaded from\n",
    "https://pjreddie.com/darknet/yolo/\n",
    "\n",
    "#### COCO Dataset and YOLO pre-trained weights\n",
    "\n",
    "- COCO Dataset from Microsoft: Common Objects in Context\n",
    "    - https://cocodataset.org/\n",
    "    - 80 different object categories\n",
    "    - 1.5M object instances\n",
    "    - Try and explore dataset online\n",
    "- We use the pretrained YOLO model, because training it from the scratch would take many hours\n",
    "    - Download the YOLO v3 weights used in the course:\n",
    "    https://drive.google.com/file/d/1yT2-zmNFymMgY42Z72LIuqMaiWvYEUQR/view?usp=sharing\n",
    "    - The model is very complex: 200 MB!!\n",
    "\n",
    "Code Source:\n",
    "https://github.com/xiaochus/YOLOv3\n",
    "\n",
    "YOLO is implemented in the Darknet framework by Joseph Redmon (the author of YOLO), but the demo file converts it to Tensorflow. The folder structure is necessary if the demo files are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from model.yolo_model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprare any image\n",
    "def process_image(img):\n",
    "    \"\"\"Resize, reduce and expand image.\n",
    "\n",
    "    # Argument:\n",
    "        img: original image.\n",
    "\n",
    "    # Returns\n",
    "        image: ndarray(64, 64, 3), processed image.\n",
    "    \"\"\"\n",
    "    image = cv2.resize(img, (416, 416),\n",
    "                       interpolation=cv2.INTER_CUBIC)\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image /= 255.\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names from file\n",
    "def get_classes(file):\n",
    "    \"\"\"Get classes name.\n",
    "\n",
    "    # Argument:\n",
    "        file: classes name for database.\n",
    "\n",
    "    # Returns\n",
    "        class_names: List, classes name.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw boxes\n",
    "def draw(image, boxes, scores, classes, all_classes):\n",
    "    \"\"\"Draw the boxes on the image.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        classes: ndarray, classes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    for box, score, cl in zip(boxes, scores, classes):\n",
    "        x, y, w, h = box\n",
    "\n",
    "        top = max(0, np.floor(x + 0.5).astype(int))\n",
    "        left = max(0, np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
    "\n",
    "        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),\n",
    "                    (top, left - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6, (0, 0, 255), 1,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "        print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n",
    "        print('box coordinate x,y,w,h: {0}'.format(box))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference: prepare image, call yolo.predict, draw results\n",
    "def detect_image(image, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect images.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "\n",
    "    # Returns:\n",
    "        image: processed image.\n",
    "    \"\"\"\n",
    "    pimage = process_image(image)\n",
    "\n",
    "    start = time.time()\n",
    "    boxes, classes, scores = yolo.predict(pimage, image.shape)\n",
    "    end = time.time()\n",
    "\n",
    "    print('time: {0:.2f}s'.format(end - start))\n",
    "\n",
    "    if boxes is not None:\n",
    "        draw(image, boxes, scores, classes, all_classes)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect objects frame-by-frame... it's slow\n",
    "def detect_video(video, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect video.\n",
    "\n",
    "    # Argument:\n",
    "        video: video file.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    video_path = os.path.join(\"videos\", \"test\", video)\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # Prepare for saving the detected video\n",
    "    sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n",
    "\n",
    "    \n",
    "    vout = cv2.VideoWriter()\n",
    "    vout.open(os.path.join(\"videos\", \"res\", video), fourcc, 20, sz, True)\n",
    "\n",
    "    while True:\n",
    "        res, frame = camera.read()\n",
    "\n",
    "        if not res:\n",
    "            break\n",
    "\n",
    "        image = detect_image(frame, yolo, all_classes)\n",
    "        cv2.imshow(\"detection\", image)\n",
    "\n",
    "        # Save the video frame by frame\n",
    "        vout.write(image)\n",
    "\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "                break\n",
    "\n",
    "    vout.release()\n",
    "    camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 09:50:50.418264: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-11 09:50:50.418734: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Thresholds are passed\n",
    "# object threshold: min confidence necessary to consider an object\n",
    "yolo = YOLO(0.6, 0.5)\n",
    "file = 'data/coco_classes.txt'\n",
    "all_classes = get_classes(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.82s\n",
      "class: person, score: 0.64\n",
      "box coordinate x,y,w,h: [2523.89198542 1482.56196737  619.40865219 1302.60187244]\n",
      "class: bicycle, score: 0.84\n",
      "box coordinate x,y,w,h: [2877.69538164 2008.9804821  1303.69913578  717.74824047]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is quite slow, not realtime (90 seconds on my Mac with a large test image)\n",
    "f = 'jingxiang-gao-489454-unsplash.jpg'\n",
    "path = 'images/test/'+f\n",
    "image = cv2.imread(path)\n",
    "image = detect_image(image, yolo, all_classes)\n",
    "cv2.imwrite('images/res/' + f, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect videos one at a time in videos/test folder    \n",
    "# video = 'library1.mp4'\n",
    "# detect_video(video, yolo, all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
