# PEFT: Parameter-Efficient Fine-Tuning

[PEFT (Parameter-Efficient Fine-Tuning)](https://huggingface.co/docs/peft/index) is

> a library for efficiently adapting large pretrained models to various downstream applications without fine-tuning all of a modelâ€™s parameters because it is prohibitively costly. PEFT methods only fine-tune a small number of (extra) model parameters - significantly decreasing computational and storage costs - while yielding performance comparable to a fully fine-tuned model. This makes it more accessible to train and store large language models (LLMs) on consumer hardware.

I decided to move this section to another repository:

[mxagar/generative_ai_udacity](https://github.com/mxagar/generative_ai_udacity)

See you there!