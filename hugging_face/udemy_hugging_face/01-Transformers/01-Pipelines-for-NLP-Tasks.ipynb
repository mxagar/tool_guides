{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89da7e6-431a-4659-a5b3-45323d11fd03",
   "metadata": {},
   "source": [
    "# Pipelines for NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d9d1e3-05e1-456d-b564-5d096896a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf038c7c-13ce-4231-8acb-2a6b8de67de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41.1\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc51c2-1efd-4811-929a-54ef8424c30c",
   "metadata": {},
   "source": [
    "## Loading Tasks\n",
    "\n",
    "The task defining which pipeline will be returned. Currently accepted tasks are:\n",
    "    \n",
    "    - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
    "    - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
    "    - `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
    "    - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n",
    "    - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n",
    "    - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
    "    - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
    "    - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
    "    - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n",
    "    - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n",
    "    - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n",
    "    - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
    "    - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
    "    - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
    "    - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
    "    - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
    "      [`TextClassificationPipeline`].\n",
    "    - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
    "    - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
    "    - `\"translation\"`: will return a [`TranslationPipeline`].\n",
    "    - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
    "    - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n",
    "    - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n",
    "    - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
    "    - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n",
    "    - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa893bc-026c-456a-99f0-8f56a47da96e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification \n",
    "\n",
    "### Default Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3498239-01f0-49b1-bf3e-d9cba22d41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998236298561096}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(task=\"text-classification\")\n",
    "pipe(\"This restaurant is ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88492a4-003a-4387-9590-0f3f621278ba",
   "metadata": {},
   "source": [
    "### Specific Models\n",
    "\n",
    "Perhaps you want to use a different model for different categories or text types, for example, financial news: https://huggingface.co/ProsusAI/finbert\n",
    "\n",
    "You can explore more details in the paper: https://arxiv.org/pdf/1908.10063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcf0966e-892f-46ca-9321-c0b31c9862ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf85b86-1132-4ef7-80c8-36e729be2910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9350943565368652}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Shares of food delivery companies surged despite the catastrophic impact of coronavirus on global markets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6eca0d8e-1d32-4801-945a-34e9e7bbf83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = ['Gonna buy AAPL, its about to surge up!',\n",
    "          'Gotta sell AAPL, its gonna plummet!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfc8d3e1-d7d4-457f-a61c-25c023f4851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.98028564453125},\n",
       " {'label': 'NEGATIVE', 'score': 0.9993641972541809}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8be7b-2cb7-425d-ae25-fa0b57f67f6a",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "Let's explore another NLP task, such as NER - Named Entity Recognition\n",
    "\n",
    "**Note, this is a much larger model! If you run this it will download about 1.5 GB on to your computer inside of a cache folder!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1486daa6-6108-4179-8fd3-682c17ad8f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "293aa275-9fde-4017-9345-ce7a4debf315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b2f9e9de00429fb1ba40b4027eda79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcial\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Marcial\\.cache\\huggingface\\hub\\models--dbmdz--bert-large-cased-finetuned-conll03-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdcae02852c4253818476e54cbdb2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4759c05fd8741ea8d62173a482c9672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e11245e7d04a88aebbbc2f60ae9fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_tag_pipe = pipeline('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbaaa69a-9dab-42a3-a1f5-1b109251c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ner_tag_pipe(\"After working at Tesla I started to study Nikola Tesla a lot more, especially at university in the USA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ad075ab-d2ad-46e1-8bb6-4c5f710c9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.save_pretrained('my_local_text_classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1be4c2c4-c1ae-446a-9ce3-680934e7da9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-ORG',\n",
       "  'score': 0.9137762,\n",
       "  'index': 4,\n",
       "  'word': 'Te',\n",
       "  'start': 17,\n",
       "  'end': 19},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.37898827,\n",
       "  'index': 5,\n",
       "  'word': '##sla',\n",
       "  'start': 19,\n",
       "  'end': 22},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99693346,\n",
       "  'index': 10,\n",
       "  'word': 'Nikola',\n",
       "  'start': 42,\n",
       "  'end': 48},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9901416,\n",
       "  'index': 11,\n",
       "  'word': 'Te',\n",
       "  'start': 49,\n",
       "  'end': 51},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.8931826,\n",
       "  'index': 12,\n",
       "  'word': '##sla',\n",
       "  'start': 51,\n",
       "  'end': 54},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9997478,\n",
       "  'index': 22,\n",
       "  'word': 'USA',\n",
       "  'start': 99,\n",
       "  'end': 102}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b446e2-8b25-4736-932b-4a7570c2570b",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ab7745a-1fe3-4e5d-89cf-8399185acd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b80cbcf17144f44bea1835dea2de0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcial\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Marcial\\.cache\\huggingface\\hub\\models--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749900b2170e48bd889109b0a4c6f370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ed1492d7b744aa8b6cf6997e1b77b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c8aeb8ce0946ff830328894eacc0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94669abadc4644c3b20481f1e9a07036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_bot = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4380b8e5-4807-48da-bd3e-65e78c42e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "D-Day, marked on June 6, 1944, stands as one of the most significant military operations in history, \n",
    "initiating the Allied invasion of Nazi-occupied Europe during World War II. Known as Operation Overlord, \n",
    "this massive amphibious assault involved nearly 160,000 Allied troops landing on the beaches of Normandy, \n",
    "France, across five sectors: Utah, Omaha, Gold, Juno, and Sword. Supported by over 5,000 ships and 13,000 \n",
    "aircraft, the operation was preceded by extensive aerial and naval bombardment and an airborne assault. \n",
    "The invasion set the stage for the liberation of Western Europe from Nazi control, despite the heavy \n",
    "casualties and formidable German defenses. This day not only demonstrated the logistical prowess \n",
    "and courage of the Allied forces but also marked a turning point in the war, leading to the eventual \n",
    "defeat of Nazi Germany.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c185e089-0966-44b6-b4d8-882faf504e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What were the five beach sectors on D-Day?\"\n",
    "\n",
    "result = qa_bot(question=question,context=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d1918a0-70f3-4d6c-8a17-bac0d07a9761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9430820345878601,\n",
       " 'start': 345,\n",
       " 'end': 379,\n",
       " 'answer': 'Utah, Omaha, Gold, Juno, and Sword'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536e540-4080-4135-84e8-86fe13dc2fe6",
   "metadata": {},
   "source": [
    "## Translations\n",
    "\n",
    "Translates from one language to another.\n",
    "\n",
    "This translation pipeline can currently be loaded from pipeline() using the following task identifier: \"translation_xx_to_yy\".\n",
    "\n",
    "The models that this pipeline can use are models that have been fine-tuned on a translation task. See the up-to-date list of available models on www.huggingface.co/models.  \n",
    "\n",
    "Note: You would typically call a specific model for translations: https://huggingface.co/models?pipeline_tag=translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f282e5-1f0e-44ca-9b92-22b211208274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453587fb51494963bf1c3ba521c405f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcial\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Marcial\\.cache\\huggingface\\hub\\models--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e099a45ebcfa45c48dfecbcfb3eec137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6607a675437748f586b034cbcbebd046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaea7f972ce4f968a30bcf0c8cf7a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b2cfc97ada4a41bb3cefb2e2b95170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcial\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translate = pipeline('translation_en_to_fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c1074c-d1c2-4957-9a32-bb0275b9a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcial\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result = translate(\"Hello, my name is Jose. What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57e175b-c6e3-4645-941d-2d415295ff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Bonjour, mon nom est Jose, quel est votre nom ?'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "619c77f5-9eda-47a0-b721-2bf4efa9cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = translate(\"Hello, my name is Jose.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10eea677-5ac7-477f-a67e-8f36c31e2acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Bonjour, mon nom est Jose.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb287c23-f3e2-47e9-b92c-a0714937e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = translate(\"Hello, I am called Jose.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca2a23c2-eed8-45ef-9d96-208dc2370b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"Bonjour, je m'appelle Jose.\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b3d58-694b-4a0e-808d-84be7d5745ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
